<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="article"/>
<title>ardatasc.github.io</title>
<link rel="icon" href="../../favicon.png" type="image/x-icon">
<link rel="preconnect" href="https://fonts.googleapis.com/">
<link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
<link rel="preconnect" href="https://fonts.googleapis.com/">
<link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono&display=swap.css" rel="stylesheet">
<link rel="preconnect" href="https://fonts.googleapis.com/">
<link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono&amp;display=swap" rel="stylesheet">
<link rel="stylesheet" href="../../theme.min.7363202e6ba39c3b4caca8b218f6f6631256ed7a41cd2f8bf46550651b07cb31.css" integrity="">
</head>
<body>
  <div class="header">
  <div class="header-content">
  <div class="header-content-title">
  ardatasc
  </div>
  <div class="header-content-nav">
  <div class="header-content-nav-item">
  <a href="../../c.html">content</a>
  </div>
  <div class="header-content-nav-item">
  <a href="../../about.html">about</a>
  </div>
  </div>
  </div>
  </div>
<div class="content-container">
<div class="content"><h1 id="vm-networking--libvirt--bridge-">VM Networking ( Libvirt / Bridge )</h1>
<p>When working with virtual machines via libvirt, it is common to initially spin
them up in such a way that allows inter-communication on their host
(hypervisor). Namely, VMs can talk to VMs on the same host. However, as you add
more hypervisors to your homelab or datacenter, you will likely want VMs to
be routable to the larger LAN. Exploring these network models and routability
will be the focus of this post.</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
<iframe src="https://web.archive.org/web/20240228151529if_/https://www.youtube.com/embed/6435eNKpyYw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>
<p>When using a stack like libvirt/qemu/kvm, there are multiple network models
available to you. Libvirt provides a &quot;default&quot; network, which enables VMs to be
routable within their host (hypervisor). In order to make VMs routable to the
larger LAN, you can introduce a <a href="https://web.archive.org/web/20240228151529/https://en.wikipedia.org/wiki/Bridging_(networking)">bridge
network</a>. This post covers
both network models. Additionally, we will examine how to setup a bridge
manually, then use systemd-networkd to automate its instantiation.</p>
<p><em>This post/video assumes basic understanding of the libvirt/qemu/kvm stack. If
you do not, checkout my <a href="https://web.archive.org/web/20240228151529/https://octetz.com/docs/2020/2020-05-06-linux-hypervisor-setup">Linux Hypervisor
Setup</a>
post/video.</em></p>
<h2 id="libvirts-default-network">Libvirt's Default Network</h2>
<p>When the libvirt stack is running, you can use virsh to determine what networks
are started.</p>
<pre tabindex="0"><code>$ virsh net-list

 Name   State   Autostart   Persistent
----------------------------------------
</code></pre><p>Your system may already have started the <code>Default</code> network. If not, as is my
case above, you can start it using virsh.</p>
<pre tabindex="0"><code>$ virsh net-start default

Network default started
</code></pre><p>In my case, if I wanted the default network to autostart, I could run <code>virsh net-autostart default</code>. However, as you'll see in a later section, this network
will eventually stay <strong>disabled</strong> in favor of a bridge network created by me.</p>
<p>With the <code>Default</code> network started, a few key things have occurred.</p>
<ul>
<li>A <code>virbr0</code> bridge interface was created.
<ul>
<li>This is a &quot;virtual switch&quot; all VMs are attached to.</li>
</ul>
</li>
<li>A <code>virbr0-nic</code> interface was created and attached to the <code>virbr0</code>.
<ul>
<li>This is a dummy interface.</li>
<li><a href="https://web.archive.org/web/20240228151529/https://www.redhat.com/archives/libvirt-users/2012-September/msg00038.html">Its purpose it to give <code>virbr0</code> a MAC adddress</a>.</li>
</ul>
</li>
<li><a href="https://web.archive.org/web/20240228151529/https://en.wikipedia.org/wiki/Dnsmasq"><code>dnsmasq</code></a> was started.
<ul>
<li>dnsmasq will work as a local DHCP server.</li>
<li>The config is at <code>/var/lib/libvirt/dnsmasq/default.conf</code>.</li>
</ul>
</li>
</ul>
<p>Visually, these changes and wiring looks as follows.</p>
<a href="https://web.archive.org/web/20240228151529/https://octetz.s3.us-east-2.amazonaws.com/vm-net/default-bridge-wiring.png" target="octetz-img">
<img src="https://web.archive.org/web/20240228151529im_/https://octetz.s3.us-east-2.amazonaws.com/vm-net/default-bridge-wiring.png">
</a>
<p>Now you can start VMs that use the <code>Default</code> network. If you're spinning up new
VMs, assuming you don't modify network settings, it's likely <code>Default</code> will be
used. To check existing VMs, use virsh to validate the network settings.</p>
<pre tabindex="0"><code>$ virsh dumpxml octetz2 | grep -i &#39;network=&#39;

&lt;source network=&#39;default&#39;
portid=&#39;093d03c1-7bb1-45e7-a528-ece5b0e5b47b&#39;
bridge=&#39;virbr0&#39;/&gt;
</code></pre><p>With the VM, in my case <code>octetz2</code>, verified to be using <code>Default</code>, you can start
the VM.</p>
<pre tabindex="0"><code>$ virsh start octetz2

Domain octetz2 started
</code></pre><p>With the VM started, a few key things have occurred.</p>
<ul>
<li>A <code>vnet0</code> <a href="https://web.archive.org/web/20240228151529/https://en.wikipedia.org/wiki/TUN/TAP">tap interface</a> is created and attached to <code>virbr0</code>.
<ul>
<li>This interface attached to the <code>qemu-system-x86_64</code> process.</li>
<li>It enables traffic to flow between the VM to the host's network stack.</li>
<li>All new VMs get one of these interfaces. The next VM would get <code>vnet1</code>.</li>
<li>Since <code>vnet*</code> interfaces are attached to the bridge VMs are routable in the
host.</li>
</ul>
</li>
<li>A new <code>qemu-system-x86_64</code> process is started for the VM.
<ul>
<li>
<p>This process is attached to the <code>vnet0</code> tap interface.</p>
</li>
<li>
<p>By identifying a VMs pid and browsing its file descriptor info, you can see
this attachment.</p>
<pre tabindex="0"><code>$ ps aux | grep -i &#39;name guest=octetz2&#39;
12562 ... /usr/bin/qemu-system-x86_64 -name guest=octetz2 ...

# cat /proc/12562/fdinfo/32
pos:    90
flags:  0104002
mnt_id: 25
iff:    vnet0
</code></pre></li>
</ul>
</li>
<li>An IP address is leased to the node.
<ul>
<li>This lease comes from <code>dnsmasq</code>.</li>
</ul>
</li>
</ul>
<p>With that, you now have an internal (to the host) VM network! This can be a
great setup when running VMs, that don't need to be reached by external hosts,
on your desktop. Another benefit of managing the entire network through libvirt is
<code>virsh</code> can tell you about the DHCP leases that were made. Assuming a second VM
is launched, the leases may look as follows.</p>
<pre tabindex="0"><code>$ virsh net-dhcp-leases default

 Expiry Time           MAC address         Protocol   IP address          Hostname
 ---------------------------------------------------------------------------------
 2020-11-14 13:41:09   52:54:00:2a:22:19   ipv4       192.168.122.4/24    ubuntu-server
 2020-11-14 13:38:54   52:54:00:b9:fe:a5   ipv4       192.168.122.96/24   arda
</code></pre><p>With the above two VMs running, a high-level look at the network is the
following.</p>
<a href="https://web.archive.org/web/20240228151529/https://octetz.s3.us-east-2.amazonaws.com/vm-net/default-net-arch.png" target="octetz-img">
<img src="https://web.archive.org/web/20240228151529im_/https://octetz.s3.us-east-2.amazonaws.com/vm-net/default-net-arch.png">
</a>
<p>A primary issue with this network layout is the VM network is entirely isolated
from the LAN network the host is connected to. If you took the above host and
multiplied it, it is likely you'd want VMs, wherever they run, to be able to
send traffic to and from each other. I'll tackle this in the next section,
Bride Networking.</p>
<h2 id="bridge-networking">Bridge Networking</h2>
<p>In the previous example, a bridge network <em>was</em> in play. In this next example,
you'll be creating a bridge network on the host instead of libvirt. You'll then
bind the host's existing interfaces to it. Lastly, you'll configure VMs to
attach to this new bridge, as if they are plugging into an internal switch on
the host. In this configuration, VMs will be able to respond to ARP requests on
the layer 2 segment in effect making them routable to the LAN. In this section
you'll walk through each step manually to aid in understanding how this network
layout works.</p>
<p>In order to make this network model work, you <strong>must</strong> ensure the following.</p>
<ul>
<li>No network management daemon is enabled.
<ul>
<li>Tools like <a href="https://web.archive.org/web/20240228151529/https://wiki.archlinux.org/index.php/NetworkManager">NetworkManager</a> and <a href="https://web.archive.org/web/20240228151529/https://wiki.archlinux.org/index.php/Systemd-networkd">systemd-networkd</a> should be off.</li>
<li>They <strong>will</strong> conflict with this manual configuration.</li>
</ul>
</li>
<li>Your physical adapter is an ethernet device and not wireless card.
<ul>
<li>Wireless drivers will either not support this configuration or will require
additional work.</li>
</ul>
</li>
<li>Your host(s) have no modifications made to their interfaces or route tables.
<ul>
<li>Beyond what is autoconfigured for the network hardware detected by Linux.</li>
<li>I recommend you disable the Default network if you turned it on in the
previous section.</li>
<li>You may consider rebooting your machine to ensure you're starting fresh.</li>
</ul>
</li>
</ul>
<p>With the above complete, take a look at your existing interfaces to understand
where you are starting from.</p>
<pre tabindex="0"><code>$ ip a s

1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever

2: eno1: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000
    link/ether 74:d4:35:ed:79:d7 brd ff:ff:ff:ff:ff:ff
    altname enp0s25

3: wlp5s0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000
    link/ether d8:f2:ca:d5:8c:b6 brd ff:ff:ff:ff:ff:ff
</code></pre><p>The host I am working with has a ethernet card, represented by <code>eno1</code>, and a
WIFI card (will not be used), represented by <code>wlp5s0</code>. The state of all these
interfaces is DOWN because the machine has just booted and there is no
networking daemon at play. For the following setup, all work will be done with
the <code>ip</code> tool. This is the recommended approach as many other tools, such as
<code>brctl</code>, are deprecated in favor of it.</p>
<p>First you need to establish a virtual switch in the form a bridge interface.</p>
<pre tabindex="0"><code>ip link add name br0 type bridge
</code></pre><p><code>br0</code> is now your virtual switch. You want everything, including the host's
ethernet device to &quot;plug&quot; into it. To do this, you'll bind your ethernet
device's interface to <code>br0</code>.</p>
<pre tabindex="0"><code>ip link set eno1 master br0
</code></pre><p><code>br0</code> needs an IP address. Normally you'd rely on DHCP to provide this, but I
demonstrate that until the next section. For now, assign an IP to the interface and
setup its broadcast domain (brd). Make sure this IP is not in use elsewhere in
your network.</p>
<pre tabindex="0"><code>ip addr add 192.168.4.7/16 dev br0 brd 192.168.255.255
</code></pre><p>While an IP is in place, <code>br0</code> and <code>eno1</code> are still <code>DOWN</code>. Next, change the link
state of both to <code>UP</code>.</p>
<pre tabindex="0"><code>ip link set up eno1 &amp;&amp;\
ip link set up br0
</code></pre><p>Now the interfaces are up. If all went correctly, you can use another host on
the LAN and run an <a href="https://web.archive.org/web/20240228151529/https://octetz.com/c/vm-networks/TODO">arping</a> against the IP address you assigned and verify this
host's MAC address responds.</p>
<pre tabindex="0"><code>root@some-random-computer [ ~ ]# arping -I eth0 192.168.4.7

ARPING 192.168.4.7 from 192.168.2.91 eth0
Unicast reply from 192.168.4.7 [3A:11:EC:A4:CC:8D]  0.759ms
Unicast reply from 192.168.4.7 [3A:11:EC:A4:CC:8D]  0.816ms
</code></pre><p>The host is now reachable, however it can't reach outside the LAN. This is
because there is <strong>default</strong> route established for traffic that is outside of
192.168.0.0/16. This can be seen by looking at the route table.</p>
<pre tabindex="0"><code>$ route

Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
192.168.0.0     0.0.0.0         255.255.0.0     U     0      0        0 br0
route -n
</code></pre><p>Add a route for the default gateway pointed at your router's gateway IP.</p>
<pre tabindex="0"><code>route add default gw 192.168.1.1
</code></pre><p>Now verify your host can ping hosts outside the LAN CIDR.</p>
<pre tabindex="0"><code>$ ping google.com

PING google.com (172.217.11.238) 56(84) bytes of data.
64 bytes from den02s01-in-f14.1e100.net (172.217.11.238): icmp_seq=1 ttl=117 time=4.27 ms
64 bytes from den02s01-in-f14.1e100.net (172.217.11.238): icmp_seq=2 ttl=117 time=4.08 ms
</code></pre><p>With all the current pieces in place, you now have the following components
wired up.</p>
<a href="https://web.archive.org/web/20240228151529/https://octetz.s3.us-east-2.amazonaws.com/vm-net/full-br-arch.png" target="octetz-img">
<img src="https://web.archive.org/web/20240228151529im_/https://octetz.s3.us-east-2.amazonaws.com/vm-net/full-br-arch.png">
</a>
<p>Now you have a bridge network setup that VMs can be attached to! If you are
ready to start attaching VMs, skip ahead to the <em>Attaching VMs to the Bridge</em>
section. Otherwise, I'll be explaining how to automate this process in the next
section.</p>
<h2 id="automating-bridge-setup">Automating Bridge Setup</h2>
<p>All the work in the previous section was for learning purposes and
realistically you'll want your host configured to automatically setup this
bridge configuration. There are a variety of ways to accomplish this and most
vary based on your distribution. However, most server distributions leverage
<code>systemd-networkd</code> for their networking. By automating the bridge configuration
in <code>systemd-networkd</code>, you can setup a process that is portable across most
distributions.</p>
<p>First, you should create the file <code>/etc/systemd/network/br.netdev</code> and set it up
to create the same interface we did in the previous section.</p>
<pre tabindex="0"><code># file is /etc/systemd/network/br.netdev

[NetDev]
Name=br0
Kind=bridge
</code></pre><p>Next you must create <code>/etc/systemd/network/1-br0-bind.network</code> instructing
the ethernet interface to bind to the bridge.</p>
<pre tabindex="0"><code># file is 1-br0-bind.network

[Match]
Name=eno1

[Network]
Bridge=br0
</code></pre><p>Lastly create <code>/etc/systemd/network/2-br0-dhcp.network</code> instructing
systemd-networkd to do a DHCP look, providing <code>br0</code> an IP lease.</p>
<pre tabindex="0"><code># file is /etc/systemd/network/2-br0-dhcp.network

[Match]
Name=br0

[Network]
DHCP=ipv4
</code></pre><p>I prefer to label the <code>.network</code> files with a number because they are
lexicographically evaluated and you want the ethernet interface to be bound before
requesting a DHCP lease. <em>However, I am not sure what the behavior would be if
these were evaluated in the wrong order</em>.</p>
<p>To make this changes take effect, enable the <code>systemd-networkd</code> unit, which
ensures it launches at start up.</p>
<pre tabindex="0"><code>systemctl enable systemd-networkd
</code></pre><p>After the machine re-starts, you can verify all the pieces are in place. See the
final image of the last section for reference.</p>
<h2 id="attaching-vms-to-the-bridge">Attaching VMs to the Bridge</h2>
<p>From this point on, VMs can be created on the host <strong>without starting</strong> the
<code>Default</code> network. Instead, simply start VMs and specify the bridge interface
you want to attach them to.</p>
<pre tabindex="0"><code>virt-install \
  --name testvm \
  --ram 2048 \
  --disk path=/var/lib/libvirt/images/u19.qcow2,size=8 \
  --vcpus 2 \
  --os-type linux \
  --os-variant generic \
  --console pty,target_type=serial \
  --bridge=br0 \
  --cdrom /var/lib/libvirt/isos/ubuntu-18.04.4-live-server-amd64.iso
</code></pre><p>If you have a fancy managed switch, you can likely log into its management panel
and see that on a single port the hypervisor and VMs are both seen as unique MAC
addresses.</p>
<a href="https://web.archive.org/web/20240228151529/https://octetz.s3.us-east-2.amazonaws.com/vm-net/switch-wiring.png" target="octetz-img">
<img src="https://web.archive.org/web/20240228151529im_/https://octetz.s3.us-east-2.amazonaws.com/vm-net/switch-wiring.png">
</a>
<p>Now that everything is wired together, you now have a network setup that looks
as follows.</p>
<a href="https://web.archive.org/web/20240228151529/https://octetz.s3.us-east-2.amazonaws.com/vm-net/full-arch.png" target="octetz-img">
<img src="https://web.archive.org/web/20240228151529im_/https://octetz.s3.us-east-2.amazonaws.com/vm-net/full-arch.png">
</a>
</div>
<div class="content-toc">
<h3>Contents</h3>
<nav id="TableOfContents">
<ul>
<li><a href="index.html#libvirts-default-network">Libvirt's Default Network</a></li>
<li><a href="index.html#bridge-networking">Bridge Networking</a></li>
<li><a href="index.html#automating-bridge-setup">Automating Bridge Setup</a></li>
<li><a href="index.html#attaching-vms-to-the-bridge">Attaching VMs to the Bridge</a></li>
</ul>
</nav>
</div>
</div>
</body>
</html>
<!--
     FILE ARCHIVED ON 15:15:29 Feb 28, 2024 AND RETRIEVED FROM THE
     INTERNET ARCHIVE ON 03:17:31 Sep 10, 2024.
     JAVASCRIPT APPENDED BY WAYBACK MACHINE, COPYRIGHT INTERNET ARCHIVE.

     ALL OTHER CONTENT MAY ALSO BE PROTECTED BY COPYRIGHT (17 U.S.C.
     SECTION 108(a)(3)).
-->
<!--
playback timings (ms):
  captures_list: 0.407
  exclusion.robots: 0.015
  exclusion.robots.policy: 0.006
  esindex: 0.008
  cdx.remote: 8.432
  LoadShardBlock: 64.498 (3)
  PetaboxLoader3.datanode: 80.908 (4)
  load_resource: 204.986
  PetaboxLoader3.resolve: 147.316
-->
