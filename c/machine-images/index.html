<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="article"/>
<title>ardatasc.github.io</title>
<link rel="icon" href="../../favicon.png" type="image/x-icon">
<link rel="preconnect" href="https://fonts.googleapis.com/">
<link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
<link rel="preconnect" href="https://fonts.googleapis.com/">
<link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono&display=swap.css" rel="stylesheet">
<link rel="preconnect" href="https://fonts.googleapis.com/">
<link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono&amp;display=swap" rel="stylesheet">
<link rel="stylesheet" href="../../theme.min.7363202e6ba39c3b4caca8b218f6f6631256ed7a41cd2f8bf46550651b07cb31.css" integrity="">
</head>
<body>
  <div class="header">
  <div class="header-content">
  <div class="header-content-title">
  ardatasc
  </div>
  <div class="header-content-nav">
  <div class="header-content-nav-item">
  <a href="../../c.html">content</a>
  </div>
  <div class="header-content-nav-item">
  <a href="../../about.html">about</a>
  </div>
  </div>
  </div>
  </div>
<div class="content-container">
<div class="content"><h1 id="preparing-machine-images-for-qemukvm">Preparing Machine Images for qemu/KVM</h1>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
<iframe src="https://web.archive.org/web/20240228164431if_/https://www.youtube.com/embed/6ccpDwT1qnw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>
<p>In a <a href="https://web.archive.org/web/20240228164431/https://octetz.com/docs/2020/2020-05-06-linux-hypervisor-setup">previous post</a>, I covered using libvirt+qemu+kvm to manage virtual machines. Once you use these tools for a while, you get to a point of needing to setup images such that you can easily clone them. These can be thought of as 'base' images. A base image often contains the operating system, packages, and (possibly) configuration for each instance to build on. For example, let's assume you are setting up infrastructure to run Kubernetes clusters. In order to run Kubernetes, there are some key components expected on each machine. Thus, a viable base image might look like:</p>
<ul>
<li>Linux Operating System (e.g. Ubuntu)</li>
<li>A container runtime (e.g. containerd)</li>
<li>The Kubernetes agent (kubelet)</li>
<li>Swap disabled (<a href="https://web.archive.org/web/20240228164431/https://github.com/kubernetes/kubernetes/issues/53533">required by Kubernetes</a>)</li>
</ul>
<p>Along with the above, there is some clean-up we may need to do before blessing something as a base image. Consider aspects of the host such as:</p>
<ul>
<li><strong>hostname</strong>: Persisted in <code>/etc/hostname</code>, typically we want unique hostnames per VM instance.</li>
<li><strong>DHCP lease</strong>: Whether this is persisted or not may depend on your DHCP client. In the case of systemd-networkd, it is stored in <code>/run</code>, which is often not persisted since its underlying file system is <a href="https://web.archive.org/web/20240228164431/https://en.wikipedia.org/wiki/Tmpfs">tmpfs</a>. Regardless, some operating systems, such as Ubuntu, default to use a <a href="https://web.archive.org/web/20240228164431/http://manpages.ubuntu.com/manpages/bionic/man5/machine-id.5.html">machine-id</a> for the lease. If the machine-id is duplicated in your clones, your VMs may end up with the same IP addresses!</li>
</ul>
<p>In summary, work needs to be done to make an image viable for cloning. In this post, I am going to break down the manual approach to creating these images. In a future post, we'll explore achieving this with more robust automation.</p>
<h2 id="manual-image-creation">Manual Image Creation</h2>
<p>While there is merit in the idea of &quot;automating everything&quot;, sometimes I just want to run some experiments. In these cases, I'm not interested in fancy automation. I just want to hand craft a VM image the same way you might make a fancy cup of coffee â˜•. On a more serious note, doing this manually is not only viable for experiments, but also as a learning tool.</p>
<p>I cover a variety of image creation methods in my <a href="https://web.archive.org/web/20240228164431/https://octetz.com/docs/2020/2020-05-06-linux-hypervisor-setup/">Linux Hypervisor Setup (libvirt/qemu/kvm)</a> post. Here I'm going to use some command line utilities to get it knocked out quick.</p>
<h3 id="install-the-operating-system">Install the Operating System</h3>
<ol>
<li>
<p>Download the installation media.</p>
<pre tabindex="0"><code>wget https://releases.ubuntu.com/20.04.1/ubuntu-20.04.1-live-server-amd64.iso \
  -O /var/lib/libvirtd/isos/ubuntu-20.04.1.iso
</code></pre><p><code>/var/lib/libvirtd/isos</code> is the arbitrary location I created for storing my install media.</p>
</li>
<li>
<p>Install the operating system.</p>
<pre tabindex="0"><code>virt-install \
  --name u20 \
  --ram 2048 \
  --disk path=/var/lib/libvirt/images/u20.qcow2,size=16 \
  --vcpus 2 \
  --cdrom /var/lib/libvirt/isos/ubuntu-20.04.1.iso
</code></pre><p>This will trigger the opening of <a href="https://web.archive.org/web/20240228164431/https://linux.die.net/man/1/virt-viewer">virt-viewer</a>, if installed. virt-viewer will provide a graphical connection to interact with the installer.</p>
</li>
<li>
<p>Proceed with the install.</p>
<p><img src="https://web.archive.org/web/20240228164431im_/https://octetz.s3.us-east-2.amazonaws.com/machine-images/u20-install.png" alt="https://octetz.s3.us-east-2.amazonaws.com/machine-images/u20-install.png"></p>
<p>Be sure to select the install SSH server option!</p>
</li>
<li>
<p>Let the machine reboot after install.</p>
</li>
</ol>
<h3 id="update-the-system-and-install-packages">Update the System and Install Packages</h3>
<p>Now that the operating system is installed, we can SSH in and begin configuring the &quot;base&quot; system. This will include updating existing packages, installing new ones, and doing arbitrary configuration. In this case, we'll continue to configure under the assumption the base image will be used for Kubernetes clusters.</p>
<ol>
<li>
<p>Find the server's IP.</p>
<pre tabindex="0"><code>virsh net-dhcp-leases default

 Expiry Time           MAC address         Protocol   IP address           Hostname        Client ID or DUID
-----------------------------------------------------------------------------------------------------------------------------------------------------
 2020-10-18 17:23:36   52:54:00:b2:a4:73   ipv4       192.168.122.123/24   u20             ff:56:50:4d:98:00:02:00:00:ab:11:c5:51:32:62:67:22:d8:d0
</code></pre><p>This assumes you're using the default network, or one fully managed by libvirt. Alternatively, you can use a VNC connection to the host (e.g. virt-viewer) and get the IP by running <code>ip a s</code>.</p>
</li>
<li>
<p><code>ssh</code> into the server.</p>
<pre tabindex="0"><code>ssh <a href="https://web.archive.org/web/20240228164431/https://octetz.com/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="6e04011d062e5f575c405f5856405f5c5c405f5c5d">[email&#160;protected]</a>
</code></pre></li>
<li>
<p>Run commands, or a script, that updates the system and installs your packages.</p>
<pre tabindex="0"><code>#!/bin/bash
# This script updates an Ubuntu system and installs relevant packages for k8s
# Run this is root
apt update
apt upgrade -y

# install and configure docker
# instructions from:
# https://kubernetes.io/docs/setup/production-environment/container-runtimes/
apt install -y \
  apt-transport-https ca-certificates curl software-properties-common gnupg2
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
add-apt-repository \
  &#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) \
  stable&#34;
sudo apt-get update &amp;&amp; sudo apt-get install -y \
  containerd.io=1.2.13-2 \
  docker-ce=5:19.03.11~3-0~ubuntu-$(lsb_release -cs) \
  docker-ce-cli=5:19.03.11~3-0~ubuntu-$(lsb_release -cs)
cat &lt;&lt;EOF | sudo tee /etc/docker/daemon.json
{
  &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;],
  &#34;log-driver&#34;: &#34;json-file&#34;,
  &#34;log-opts&#34;: {
    &#34;max-size&#34;: &#34;100m&#34;
  },
  &#34;storage-driver&#34;: &#34;overlay2&#34;
}
EOF
mkdir -p /etc/systemd/system/docker.service.d
systemctl daemon-reload
systemctl restart docker
systemctl enable docker

# Install kubelet, kubeadm, and kubectl
sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
cat &lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
apt update
apt  install -y kubelet kubeadm kubectl
# mark these packages to ensure they don&#39;t upgrade without intervention
apt-mark hold kubelet kubeadm kubectl
</code></pre></li>
<li>
<p>Do any system configuration desired. To support Kubernetes, we may wish to disable swap by entering the file system table at <code>/etc/fstab</code> and removing it.</p>
<pre tabindex="0"><code># / was on /dev/ubuntu-vg/ubuntu-lv during curtin installation
/dev/disk/by-id/dm-uuid-LVM-xDSiqbDt3eDJGDXiX0NjBde4J9nd6YN9yDgEqxDIldxEIBVK96KuOISEhznBUD9l / ext4 defaults 0 0
# /boot was on /dev/vda2 during curtin installation
/dev/disk/by-uuid/dac500dc-5be1-4cd5-9ed8-f07b858cb1d6 /boot ext4 defaults 0 0

# !! delete or comment this line !!
#/swap.img      none    swap    sw      0       0
</code></pre></li>
</ol>
<h3 id="prepare-the-image-for-cloning">Prepare the Image for Cloning</h3>
<p>In order to clone this machine successfully, you need to ensure future replicas are unique in how they spin up. Take for example the IP address leased to this VM. The ID used to request a lease from the DHCP server is generated off the machine-id (<code>/etc/machine-id</code>). Here you can see the host's CLIENTID used in requesting that lease.</p>
<a href="https://web.archive.org/web/20240228164431/https://octetz.s3.us-east-2.amazonaws.com/machine-images/duid.png" target="octetz-img">
<img class="img-center" src="https://web.archive.org/web/20240228164431im_/https://octetz.s3.us-east-2.amazonaws.com/machine-images/duid.png">
</a>
<p>You don't want this to persist in future cloned instances or else they risk leasing the same IP. This could cause 2 routable hosts with the same IP to live on the network and cause all sorts of problems. It is key to understand how the machine-id got there. On start-up <code>systemd-machine-id-setup</code> is called. However, when <code>/etc/machine-id</code> is set, the code never fires to evaluate the client-id. When <code>/etc/machine-id</code> is missing, it detects that you are running on KVM and takes the UUID from <code>/sys/class/dmi/id/product_uuid</code>. This UUID could also be seen by running <code>virsh domuuid {name-of-domain/host}</code>. The following logic facilitates this, which can be found <a href="https://web.archive.org/web/20240228164431/https://github.com/systemd/systemd/blob/90616bb962703d9d0d61e1988b302f2dae013cb5/src/core/machine-id-setup.c#L48-L78">in the systemd sourc</a>e.</p>
<pre tabindex="0"><code>if (isempty(root) &amp;&amp; running_in_chroot() &lt;= 0) {
                /* If that didn&#39;t work, see if we are running in a container,
                 * and a machine ID was passed in via $container_uuid the way
                 * libvirt/LXC does it */

                if (detect_container() &gt; 0) {
                        _cleanup_free_ char *e = NULL;

                        if (getenv_for_pid(1, &#34;container_uuid&#34;, &amp;e) &gt; 0 &amp;&amp;
                            sd_id128_from_string(e, ret) &gt;= 0) {
                                log_info(&#34;Initializing machine ID from container UUID.&#34;);
                                return 0;
                        }

                } else if (detect_vm() == VIRTUALIZATION_KVM) {

                        /* If we are not running in a container, see if we are
                         * running in qemu/kvm and a machine ID was passed in
                         * via -uuid on the qemu/kvm command line */

                        if (id128_read(&#34;/sys/class/dmi/id/product_uuid&#34;, ID128_UUID, ret) &gt;= 0) {
                                log_info(&#34;Initializing machine ID from KVM UUID.&#34;);
                                return 0;
                        }
                        /* on POWER, it&#39;s exported here instead */
                        if (id128_read(&#34;/sys/firmware/devicetree/base/vm,uuid&#34;, ID128_UUID, ret) &gt;= 0) {
                                log_info(&#34;Initializing machine ID from KVM UUID.&#34;);
                                return 0;
                        }
                }
        }
</code></pre><p>To ensure the above logic executes on a new clone, you must empty the file <code>/etc/machine-id</code>.</p>
<ol>
<li>
<p>Flush the contents of <code>/etc/machine-id</code>.</p>
<pre tabindex="0"><code>echo -n &gt; /etc/machine-id
</code></pre></li>
</ol>
<p>Now that the machine-id is emptied, it will be set on every new clone. If you reboot this &quot;base&quot; image at some point, note that the machine-id <strong>will be set again</strong>, which may force you to go through the above. Some will take this a step further and ensure the base image is set to use the interface's mac address as the DUID for DHCP rather than the machine-id. This is perfectly acceptable and would achieve the same result of ensuring unique IPs. However, I recommend you still empty the machine-id as describe above to ensure clones are initialized properly.</p>
<p>Next you should consider the hostname. This value is stored in <code>/etc/hostname</code> and will be brought into all clones. This may or may not be an issue for you initially, but hostname can find its way to multiple places. For example, the hostname may be passed when leasing an IP from DHCP or, in Kubernetes, the hostname is used to identify each host in the cluster. Similar to IP, you may want these uniquely identifiable. Your choice of hostname is up to you. Some set the hostname to the IP of the machine. For my purposes, I like setting a random hostname that is set on boot and never changed. To do this, you can create a simple script as follows.</p>
<ol>
<li>
<p>Add the following script to <code>/usr/local/bin</code>.</p>
<pre tabindex="0"><code>#!/bin/sh
SN=&#34;hostname-init&#34;

# do nothing if /etc/hostname exists
if [ -f &#34;/etc/hostname&#34; ]; then
  echo &#34;${SN}: /etc/hostname exists; noop&#34;
  exit
fi

echo &#34;${SN}: creating hostname&#34;

# set hostname
HN=$(head -60 /dev/urandom | tr -dc &#39;a-z&#39; | fold -w 3 | head -n 1)
echo ${HN} &gt; /etc/hostname
echo &#34;${SN}: hostname (${HN}) created&#34;

# sort of dangerous, but works.
if [ -f &#34;/etc/hostname&#34; ]; then
  /sbin/reboot
fi
</code></pre></li>
<li>
<p>Set the script to be executable.</p>
<pre tabindex="0"><code>chmod +x /usr/local/bin/hostname-init.sh
</code></pre></li>
<li>
<p>Add the following systemd unit to <code>/etc/systemd/system/hostname-init.service</code>.</p>
<pre tabindex="0"><code>[Unit]
Description=Set a random hostname.
ConditionPathExists=!/etc/hostname

[Service]
ExecStart=/usr/local/bin/hostname-init.sh

[Install]
WantedBy=multi-user.target
</code></pre></li>
<li>
<p>Ensure permission are set to <code>644</code>.</p>
<pre tabindex="0"><code>chmod 644 /etc/systemd/system/hostname-init.service
</code></pre></li>
<li>
<p>Enable the unit to ensure it's evaluated on start up.</p>
<pre tabindex="0"><code>systemctl enable hostname-init
</code></pre></li>
<li>
<p>Remove the host's hostname.</p>
<pre tabindex="0"><code>rm -v /etc/hostname
</code></pre></li>
</ol>
<p>You may notice that the script and the systemd unit check for the existence of <code>/etc/hostname</code>. While redundant, I prefer they both do this check so they are not making assumptions about each other. Similar to machine-id, if this host were to reboot, a hostname would be set. With this in mind, you need to delete <code>/etc/hostname</code> again should you reboot.</p>
<p>Before shutting down the base image and beginning cloning, you should do any final clean-up that is desirable. For example, the commands you've been running may be tracked in <code>~/.bash_history</code>. Once complete, shutdown the host.</p>
<ol>
<li>
<p>Power off the host.</p>
<pre tabindex="0"><code>poweroff
</code></pre></li>
</ol>
<h2 id="creating-clones">Creating Clones</h2>
<p>There are several ways to clone the new base image. I prefer to use <a href="https://web.archive.org/web/20240228164431/https://linux.die.net/man/1/virt-clone">virt-clone</a> to quickly create VMs.</p>
<ol>
<li>
<p>Clone <code>u20</code> to <code>node0</code>.</p>
<pre tabindex="0"><code>virt-clone --original u20 \
    --name node0 \
    --file /var/lib/libvirt/images/node0.qcow2
</code></pre></li>
<li>
<p>Power on the new clone.</p>
<pre tabindex="0"><code>virsh start node0
</code></pre></li>
<li>
<p>Find the IP address given to the new node.</p>
<pre tabindex="0"><code>virsh net-dhcp-leases default                                                                                                               taco: Mon Oct 19 07:58:12 2020

IP address           Hostname   Client ID or DUID
------------------------------------------------------
192.168.122.134/24   uym        01:52:54:00:cc:50:fa &lt;== new host
192.168.122.123/24   u20        01:52:54:00:cf:44:d7 &lt;== old base image
</code></pre><p>There are several ways to determine the IP address. This method assumes libvirt is managing the network and you can lookup the DHCP leases.</p>
</li>
<li>
<p>Optionally, you can ssh in and view the systemd unit that set the hostname.</p>
<pre tabindex="0"><code>systemctl status hostname-init
</code></pre><p>While <code>/etc/hostname</code> is set, this unit will <strong>not</strong> execute again!</p>
</li>
</ol>
<h2 id="summary">Summary</h2>
<p>That is all for setting up machine images to use/clone in qemu/KVM. I hope you found this post helpful and educational. In a future post, we will explore automating this process to enable a more robust means of image creation.</p>
</div>
<div class="content-toc">
<h3>Contents</h3>
<nav id="TableOfContents">
<ul>
<li><a href="index.html#manual-image-creation">Manual Image Creation</a>
<ul>
<li><a href="index.html#install-the-operating-system">Install the Operating System</a></li>
<li><a href="index.html#update-the-system-and-install-packages">Update the System and Install Packages</a></li>
<li><a href="index.html#prepare-the-image-for-cloning">Prepare the Image for Cloning</a></li>
</ul>
</li>
<li><a href="index.html#creating-clones">Creating Clones</a></li>
<li><a href="index.html#summary">Summary</a></li>
</ul>
</nav>
</div>
</div>
<script data-cfasync="false" src="https://web.archive.org/web/20240228164431js_/https://octetz.com/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script></body>
</html>
<!--
     FILE ARCHIVED ON 16:44:31 Feb 28, 2024 AND RETRIEVED FROM THE
     INTERNET ARCHIVE ON 03:17:40 Sep 10, 2024.
     JAVASCRIPT APPENDED BY WAYBACK MACHINE, COPYRIGHT INTERNET ARCHIVE.

     ALL OTHER CONTENT MAY ALSO BE PROTECTED BY COPYRIGHT (17 U.S.C.
     SECTION 108(a)(3)).
-->
<!--
playback timings (ms):
  captures_list: 0.538
  exclusion.robots: 0.02
  exclusion.robots.policy: 0.01
  esindex: 0.035
  cdx.remote: 20.19
  LoadShardBlock: 164.102 (3)
  PetaboxLoader3.datanode: 146.167 (4)
  PetaboxLoader3.resolve: 135.574 (3)
  load_resource: 143.851
-->
